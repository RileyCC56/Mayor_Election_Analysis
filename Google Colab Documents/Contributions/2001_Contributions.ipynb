{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2001_Contributions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP79FZ9BFNknOJYzeF+voWY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssheggrud/Mod_20_Project/blob/05_Riley/2001_Contributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0_SOu8LIEc"
      },
      "source": [
        "## **2001 Indivdual Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddn5mqQ0M_R3",
        "outputId": "3eda0020-0475-48de-d48b-098842ab96d0"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.0.3'\n",
        "#spark_version = 'spark-2.4.8'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 43.1 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 88.7 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to ppa.launch\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [567 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,324 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,799 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [717 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [921 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [600 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,760 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 13.6 MB in 5s (2,691 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiP19KLKCpxR"
      },
      "source": [
        "import findspark\n",
        "findspark.add_packages('mysql:mysql-connector-java:8.0.11')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Dd_JabNFZU",
        "outputId": "eeb380d8-93e4-4d61-bd62-fb308855a720"
      },
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 14:02:40--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  5.44MB/s    in 0.2s    \n",
            "\n",
            "2021-09-14 14:02:41 (5.44 MB/s) - ‘postgresql-42.2.16.jar’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrvolWKMNFbe"
      },
      "source": [
        "# Start Spark session\n",
        "#from pyspark.sql import SparkSession\n",
        "#from pyspark.sql.functions import col\n",
        "#spark = SparkSession.builder.appName(\"FinalProject\").getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9RnA4W6GDS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2uxnkAjNFeD",
        "outputId": "5b210342-f0bb-486c-d42c-97ee59a59aca"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Individual+Contributions+2001+(UF).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Individual+Contributions+2001+(UF).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-----------+---------+------+---------+------+--------+------+----------+--------+---------------+----------+----+------+-----+-------+---------+---------+----+-----+-----+-----------------+--------------------+--------+------------------+--------+--------+----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|   CANDLAST|CANDFIRST|CANDMI|COMMITTEE|FILING|SCHEDULE|PAGENO|SEQUENCENO|   REFNO|           DATE|REFUNDDATE|NAME|C_CODE|STRNO|STRNAME|APARTMENT|BOROUGHCD|CITY|STATE|  ZIP|       OCCUPATION|             EMPNAME|EMPSTRNO|        EMPSTRNAME| EMPCITY|EMPSTATE|AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|INTERMNO|INTERMNAME|INTSTRNO|INTSTRNM|INTAPTNO|INTCITY|INTST|INTZIP|INTEMPNAME|INTEMPSTNO|INTEMPSTNM|INTEMPCITY|INTEMPST|INTOCCUPA|PURPOSECD|EXEMPTCD|ADJTYPECD|RR_IND|SEG_IND|INT_C_CODE|\n",
            "+--------+--------+------+--------+-----------+---------+------+---------+------+--------+------+----------+--------+---------------+----------+----+------+-----+-------+---------+---------+----+-----+-----+-----------------+--------------------+--------+------------------+--------+--------+----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|    2001|       5|   579|       P|     Hughes|  Michael|     B|        H|    10|     ABC|  null|      null|P0009-05|  8/8/2001 0:00|      null|null|   IND| null|   null|     null|        M|  NY|   NY|10034|             null|                null|    null|              null|    null|    null|  10|       10|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   559|       P|     Wooten|   Donald|     T|        H|    10|       D|  null|      null|P0001-01| 8/31/2001 0:00|      null|null|  OTHR| null|   null|     null|     null|null| null| null|SOCIAL CLUB OWNER|       THE ELITE ARK|      48|       WORTMAN AVE|BROOKLYN|      NY|   1|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|    RENTO|    null|     null|     N|   null|      null|\n",
            "|    2001|       5|    C6|       P|    Fabozzi|   Albert|  null|        H|     6|     ABC|  null|      null|P0003-08|  8/1/2000 0:00|      null|null|  CORP| null|   null|     null|     null|null| null| null|             null|MYOPTIC S DIVISIO...|      82|CHRISTOPHER STREET|NEW YORK|      NY| 100|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|        H|     9|     ABC|  null|      null|P0007-09|  7/5/2001 0:00|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|  25|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|        H|     9|     ABC|  null|      null|P0007-10|  7/5/2001 0:00|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null| 100|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|        H|     9|     ABC|  null|      null|P0001-08| 3/20/2001 0:00|      null|null|  UNKN| null|   null|     null|        X|null| null| null|             null|                null|    null|              null|    null|    null| 260|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|        H|     9|     ABC|  null|      null|P0001-05| 2/20/2001 0:00|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null| 300|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|    MJ|       P|   Martinez|     Juan|     D|        H|     9|     ABC|  null|      null|P0001-10|           null|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|   0|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   448|       P|    Ciafone|     John|     J|        H|    10|     ABC|  null|      null|P0003-04|           null|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|   0|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|        H|     9|     ABC|  null|      null|P0002-06| 4/24/2001 0:00|      null|null|   IND| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|1040|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|        H|     9|     ABC|  null|      null|P0003-01| 4/24/2001 0:00|      null|null|   IND| null|   null|     null|     null|null| null| null|             null|       NOT AVAILABLE|    null|              null|    null|    null| 250|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   553|       P|Atwood King|Elizabeth|  null|        H|     9|     ABC|  null|      null|P0002-01| 7/13/2001 0:00|      null|null|   IND| null|   null|     null|        K|null| null| null|             null|                null|    null|              null|    null|    null|  45|       45|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       6|   230|      NP|     Siegal|  Bernice|     D|        H|     4|     ABC|  null|      null|P0005-07|10/12/1999 0:00|      null|null|  EMPO| null|   null|     null|     null|null| null| null|             null|DISTRICT 15 INTER...|    1455|       MAIN AVENUE| CLIFTON|      NJ| 200|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       6|   230|      NP|     Siegal|  Bernice|     D|        H|     4|     ABC|  null|      null|P0005-08|10/20/1999 0:00|      null|null|  EMPO| null|   null|     null|     null|null| null| null|             null|EUREKA LODGE NO 4...|   91-31|QUEENS BLVD RM 406|ELMHURST|      NY| 100|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       6|   230|      NP|     Siegal|  Bernice|     D|        H|     4|     ABC|  null|      null|P0006-01|10/13/1999 0:00|      null|null|  EMPO| null|   null|     null|     null|null| null| null|             null|DIST 15 INTERN L ...|    1455|       MAIN AVENUE| CLIFTON|      NJ| 150|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   232|       P|     Weprin|    David|     I|        H|     8|     ABC|  null|      null|P0001-06|           null|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|   0|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   553|       P|Atwood King|Elizabeth|  null|        H|     8|     ABC|  null|      null|P0007-10|           null|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|  50|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|    F5|       P|    Montano|  Armando|  null|        H|    15|     ABC|  null|      null|P0001-01| 10/5/2001 0:00|      null|null|  UNKN| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|  25|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   232|       P|     Weprin|    David|     I|        H|    12|     ABC|  null|      null|P0001-04| 8/23/2001 0:00|      null|null| PCOMP| null|   null|     null|     null|null| null| null|             null|                null|    null|              null|    null|    null|   0|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2001|       5|   334|       P|  Gallagher|   Dennis|     P|        H|    11|     ABC|  null|      null|P0006-01| 9/12/2001 0:00|      null|null|   IND| null|   null|     null|     null|null| null| null|             null|  COVILLA ETHELRIDGE|     180|      CABRINI BLVD|NEW YORK|      NY| 200|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "+--------+--------+------+--------+-----------+---------+------+---------+------+--------+------+----------+--------+---------------+----------+----+------+-----+-------+---------+---------+----+-----+-----+-----------------+--------------------+--------+------------------+--------+--------+----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2cRNc4wNFgt",
        "outputId": "92401892-8f08-4278-e2ca-378cf4380c9b"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'CANDMI', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','INTERMNO', 'REFUNDDATE', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-----------+---------+------+---------------+----+------+---------+----+-----+-----+--------+----+---------+--------+----------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|   CANDLAST|CANDFIRST|CANDMI|           DATE|NAME|C_CODE|BOROUGHCD|CITY|STATE|  ZIP|EMPSTATE|AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|\n",
            "+--------+--------+------+--------+-----------+---------+------+---------------+----+------+---------+----+-----+-----+--------+----+---------+--------+----------+\n",
            "|    2001|       5|   579|       P|     Hughes|  Michael|     B|  8/8/2001 0:00|null|   IND|        M|  NY|   NY|10034|    null|  10|       10|       0|         2|\n",
            "|    2001|       5|   559|       P|     Wooten|   Donald|     T| 8/31/2001 0:00|null|  OTHR|     null|null| null| null|      NY|   1|        0|       0|         0|\n",
            "|    2001|       5|    C6|       P|    Fabozzi|   Albert|  null|  8/1/2000 0:00|null|  CORP|     null|null| null| null|      NY| 100|        0|       0|         2|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|  7/5/2001 0:00|null|  UNKN|     null|null| null| null|    null|  25|        0|       0|         0|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null|  7/5/2001 0:00|null|  UNKN|     null|null| null| null|    null| 100|        0|       0|         0|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null| 3/20/2001 0:00|null|  UNKN|        X|null| null| null|    null| 260|        0|       0|         0|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null| 2/20/2001 0:00|null|  UNKN|     null|null| null| null|    null| 300|        0|       0|         0|\n",
            "|    2001|       5|    MJ|       P|   Martinez|     Juan|     D|           null|null|  UNKN|     null|null| null| null|    null|   0|        0|       0|         0|\n",
            "|    2001|       5|   448|       P|    Ciafone|     John|     J|           null|null|  UNKN|     null|null| null| null|    null|   0|        0|       0|         0|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null| 4/24/2001 0:00|null|   IND|     null|null| null| null|    null|1040|        0|       0|         0|\n",
            "|    2001|       2|   366|       P|      Colon|   Willie|  null| 4/24/2001 0:00|null|   IND|     null|null| null| null|    null| 250|        0|       0|         0|\n",
            "|    2001|       5|   553|       P|Atwood King|Elizabeth|  null| 7/13/2001 0:00|null|   IND|        K|null| null| null|    null|  45|       45|       0|         2|\n",
            "|    2001|       6|   230|      NP|     Siegal|  Bernice|     D|10/12/1999 0:00|null|  EMPO|     null|null| null| null|      NJ| 200|        0|       0|         2|\n",
            "|    2001|       6|   230|      NP|     Siegal|  Bernice|     D|10/20/1999 0:00|null|  EMPO|     null|null| null| null|      NY| 100|        0|       0|         2|\n",
            "|    2001|       6|   230|      NP|     Siegal|  Bernice|     D|10/13/1999 0:00|null|  EMPO|     null|null| null| null|      NJ| 150|        0|       0|         2|\n",
            "|    2001|       5|   232|       P|     Weprin|    David|     I|           null|null|  UNKN|     null|null| null| null|    null|   0|        0|       0|         0|\n",
            "|    2001|       5|   553|       P|Atwood King|Elizabeth|  null|           null|null|  UNKN|     null|null| null| null|    null|  50|        0|       0|         2|\n",
            "|    2001|       5|    F5|       P|    Montano|  Armando|  null| 10/5/2001 0:00|null|  UNKN|     null|null| null| null|    null|  25|        0|       0|         0|\n",
            "|    2001|       5|   232|       P|     Weprin|    David|     I| 8/23/2001 0:00|null| PCOMP|     null|null| null| null|    null|   0|        0|       0|         0|\n",
            "|    2001|       5|   334|       P|  Gallagher|   Dennis|     P| 9/12/2001 0:00|null|   IND|     null|null| null| null|      NY| 200|        0|       0|         2|\n",
            "+--------+--------+------+--------+-----------+---------+------+---------------+----+------+---------+----+-----+-----+--------+----+---------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5aiRN5RNFjB",
        "outputId": "69c542ef-f6e0-4a6a-b151-69cf4587b4a3"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ELECTION', 'string'),\n",
              " ('OFFICECD', 'string'),\n",
              " ('CANDID', 'string'),\n",
              " ('CANCLASS', 'string'),\n",
              " ('CANDLAST', 'string'),\n",
              " ('CANDFIRST', 'string'),\n",
              " ('CANDMI', 'string'),\n",
              " ('DATE', 'string'),\n",
              " ('NAME', 'string'),\n",
              " ('C_CODE', 'string'),\n",
              " ('BOROUGHCD', 'string'),\n",
              " ('CITY', 'string'),\n",
              " ('STATE', 'string'),\n",
              " ('ZIP', 'string'),\n",
              " ('EMPSTATE', 'string'),\n",
              " ('AMNT', 'string'),\n",
              " ('MATCHAMNT', 'string'),\n",
              " ('PREVAMNT', 'string'),\n",
              " ('PAY_METHOD', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ0XO4BYnxgz"
      },
      "source": [
        "#Combine the Candidate first and last name columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIkq3wdqOzWV",
        "outputId": "2861b84d-78bb-4ca4-ccdc-a55560f5a1f9"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\")\n",
        "\n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Election: string (nullable = true)\n",
            " |-- OFFICECD: string (nullable = true)\n",
            " |-- CANDID: string (nullable = true)\n",
            " |-- CANCLASS: string (nullable = true)\n",
            " |-- CANDLAST: string (nullable = true)\n",
            " |-- CANDFIRST: string (nullable = true)\n",
            " |-- CANDMI: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ContributerType: string (nullable = true)\n",
            " |-- BoroughName: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- ZipCode: string (nullable = true)\n",
            " |-- ContributionState: string (nullable = true)\n",
            " |-- Amount: string (nullable = true)\n",
            " |-- MatchAmt: string (nullable = true)\n",
            " |-- PrevAmt: string (nullable = true)\n",
            " |-- PayMethod: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiXwUrr451d1"
      },
      "source": [
        "#Drop the null candidateID values\n",
        "#df2 = df1.na.drop(subset=['CandidateID']).show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p5HwOCEjlsd"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "dbyFIRMwjlzM",
        "outputId": "a2521157-fbc1-48e8-d4e8-10ca6fdc89ea"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\", df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ab9f23780e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# changing datatypes of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mudf\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDateType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Election\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Election\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OFFICECD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OFFICECD\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CandidateID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CandidateID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ZipCode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ZipCode\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Amount\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Amount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MatchAmt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MatchAmt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PrevAmt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PrevAmt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0...\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \"\"\"\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Cannot resolve column name \"CandidateID\" among (Election, OFFICECD, CANDID, CANCLASS, CANDLAST, CANDFIRST, CANDMI, Date, Name, ContributerType, BoroughName, City, State, ZipCode, ContributionState, Amount, MatchAmt, PrevAmt, PayMethod);"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1aCPuV3WPwC"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDLKVpihXzJY"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4JAvyQWRl7"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM_kC3ViNFqN"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdLbDEzQAyc"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kbDs5ApZtEu"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4uude7r_d_-"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdRMcW-9mtO"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_indiv_2001_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_indiv_2001_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAV3a6jXmJTP"
      },
      "source": [
        "#Export to Clean CSV\n",
        "clean_indiv_2001_df.toPandas().to_csv(\"Clean_Indivdual_2001.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7gDM4IKH8Y"
      },
      "source": [
        "## **2001 Committee Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hraQT1VmLOhL"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Committee+Contributions+2001+(X).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Committee+Contributions+2001+(X).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-dAX_VzLOhL"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','REFUNDDATE','INTERMNO', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btba2GO-LOhL"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3HO9e01LOhL"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\") \n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAf4vA_5jTRM"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8pcOHEWjVfK"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\",df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6S4he5LOhM"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKU4a2YeLOhM"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH99qC5LOhM"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO9XHx_6LOhM"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEmNuKUFLOhM"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myx_AWPaLOhM"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEu2eqWaDg1J"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uci_zuD5LOhM"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_comm_2001_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_comm_2001_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP38ou7rs5hY"
      },
      "source": [
        "#Export to new CSV\n",
        "clean_comm_2017_df.toPandas().to_csv(\"Clean_Committee_2001.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3PsGBmTLOhN"
      },
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "#Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://database-final.cjdbapst3wjf.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
        "config = {\"user\":\"postgres\",\n",
        "          \"password\": \"******\",\n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ4dBFJKSG5J"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "clean_indiv_2017_df.write.jdbc(url=jdbc_url, table='individual_2017', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpL71qCG1F2"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "clean_comm_2017_df.write.jdbc(url=jdbc_url, table='committee_2017', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}