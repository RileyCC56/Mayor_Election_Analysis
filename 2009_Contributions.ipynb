{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2009_Contributions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiTzQxO2oR5mmR2RnRKmml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssheggrud/Mod_20_Project/blob/05_Riley/2009_Contributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0_SOu8LIEc"
      },
      "source": [
        "## **2009 Indivdual Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddn5mqQ0M_R3",
        "outputId": "98b00bf5-b5e6-4509-b190-f9165758b1d2"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.0.3'\n",
        "#spark_version = 'spark-2.4.8'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,324 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [567 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [717 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,799 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,760 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [921 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [600 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 13.6 MB in 5s (2,894 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiP19KLKCpxR"
      },
      "source": [
        "import findspark\n",
        "findspark.add_packages('mysql:mysql-connector-java:8.0.11')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Dd_JabNFZU",
        "outputId": "e65b49cb-c28e-4d1b-99ed-1ff8b1ae853e"
      },
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 02:49:16--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-14 02:49:16 (6.57 MB/s) - ‘postgresql-42.2.16.jar’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrvolWKMNFbe"
      },
      "source": [
        "# Start Spark session\n",
        "#from pyspark.sql import SparkSession\n",
        "#from pyspark.sql.functions import col\n",
        "#spark = SparkSession.builder.appName(\"FinalProject\").getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9RnA4W6GDS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2uxnkAjNFeD",
        "outputId": "fb5ebf92-f765-4509-97d5-a30271a2fd36"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Individual+Contributions+2009+(UF).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Individual+Contributions+2009+(UF).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+-------+--------+-------------+---------+------+--------+------+----------+--------+---------+----------+------------------+------+-----+-------+---------+---------+---------+-----+-----+--------------------+-------------------+--------+--------------------+----------------+--------+----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|ELECTION|OFFICECD|RECIPID|CANCLASS|    RECIPNAME|COMMITTEE|FILING|SCHEDULE|PAGENO|SEQUENCENO|   REFNO|     DATE|REFUNDDATE|              NAME|C_CODE|STRNO|STRNAME|APARTMENT|BOROUGHCD|     CITY|STATE|  ZIP|          OCCUPATION|            EMPNAME|EMPSTRNO|          EMPSTRNAME|         EMPCITY|EMPSTATE|AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|INTERMNO|INTERMNAME|INTSTRNO|INTSTRNM|INTAPTNO|INTCITY|INTST|INTZIP|INTEMPNAME|INTEMPSTNO|INTEMPSTNM|INTEMPCITY|INTEMPST|INTOCCUPA|PURPOSECD|EXEMPTCD|ADJTYPECD|RR_IND|SEG_IND|INT_C_CODE|\n",
            "+--------+--------+-------+--------+-------------+---------+------+--------+------+----------+--------+---------+----------+------------------+------+-----+-------+---------+---------+---------+-----+-----+--------------------+-------------------+--------+--------------------+----------------+--------+----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     7|     ABC|  null|      null|R0000020|1/22/2009|      null|     Morris, Blake|   IND| null|   null|     null|        K| Brooklyn|   NY|11226|            Attorney|      Self-employed|    null|                null|        Brooklyn|      NY| 100|      100|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     7|     ABC|  null|      null|R0000022| 2/3/2009|      null|     Pikttch, Ruth|   IND| null|   null|     null|        K| Brooklyn|   NY|11214|             Retired|               null|    null|                null|        Brooklyn|      NY|  50|       50|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     7|     ABC|  null|      null|R0000024|1/22/2009|      null| Goldstein, Benita|   IND| null|   null|     null|        M| New York|   NY|10021|      Office Manager|  Mirrors by Jordan|   38-27|         28th Street|Long Island City|      NY|  40|       40|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     7|     ABC|  null|      null|R0000025|11/6/2008|      null|     GOODWIN, GWEN|   CAN| null|   null|     null|        M| New York|   NY|10029|      Make-up Artist|      Self-employed|    null|                null|        New York|      NY|  25|        0|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     7|     ABC|  null|      null|R0000035|2/26/2009|      null|   Anderson, Peter|   IND| null|   null|     null|        M| New York|   NY|10037|      Letter Carrier|U.S. Postal Service|     421|          8th Avenue|        New York|      NY|  40|       40|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     7|     ABC|  null|      null|R0000041|11/6/2008|      null|     GOODWIN, GWEN|   CAN| null|   null|     null|        M| New York|   NY|10029|      Make-up Artist|      Self-employed|    null|                null|        New York|      NY|  25|        0|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     8|     ABC|  null|      null|R0000048|3/28/2009|      null|     Perez, Andrew|   IND| null|   null|     null|        M| New York|   NY|10028|         Sales Clerk|        Barney's NY|     660|      Madison Avenue|        New York|      NY|  10|       10|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     8|     ABC|  null|      null|R0000050| 5/4/2009|      null|    Rodriguez, Ana|   IND| null|   null|     null|        M| New York|   NY|10029|        Floor Person|       CVS Pharmacy|    1500|    Lexington Avenue|        New York|      NY|  15|       15|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     8|     ABC|  null|      null|R0000052|4/14/2009|      null|  Bryant, Robert A|   IND| null|   null|     null|        Z|Hillcrest|   NY|10977|         Firefighter|            Retired|    null|                null|            null|    null| 100|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     8|     ABC|  null|      null|R0000054|3/16/2009|      null| Reinert, Pamela A|   IND| null|   null|     null|        M| New York|   NY|10029|                null|            Retired|    null|                null|            null|    null| 250|      175|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     8|     ABC|  null|      null|R0000059| 5/4/2009|      null|Palmieri, Pasquale|   IND| null|   null|     null|        M| New York|   NY|10035|            Landlord|      Self-employed|    null|                null|        New York|      NY| 500|      175|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     8|     ABC|  null|      null|R0000061| 5/2/2009|      null|       Bruno, Jo C|   IND| null|   null|     null|        M| New York|   NY|10017|             Teacher|            Retired|    null|                null|            null|    null|  25|       25|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000073|5/14/2009|      null|    Epstein, Lorie|   IND| null|   null|     null|        M| New York|   NY|10128|             Teacher|            Retired|    null|                null|            null|    null|  10|       10|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000081|5/23/2009|      null|   BROWN, FRANCINE|   IND| null|   null|     null|        M| New York|   NY|10037|    PERSONAL TRAINER|          92 St.  Y|    null|975 LEXINGTON AVENUE|        New York|      NY|  20|       20|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000083|5/23/2009|      null|    ASHANTE, OMEGA|   IND| null|   null|     null|        K| Brooklyn|   NY|11226|            MUSICIAN|      SELF EMPLOYED|    null|                null|            null|    null|  10|       10|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000085|5/23/2009|      null| Reinert, Pamela A|   IND| null|   null|     null|        M| New York|   NY|10029|                null|            Retired|    null|                null|            null|    null|  20|        0|     250|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000087|5/23/2009|      null|      SOLER, JAMES|   IND| null|   null|     null|        M| New York|   NY|10029|                null|            RETIRED|    null|                null|            null|    null|  50|       50|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000089|5/23/2009|      null|   DELUCA, ANTHONY|   IND| null|   null|     null|        M| New York|   NY|10025|ART FABRICATION /...|      SELF-EMPLOYED|    null|                null|        New York|      NY|  25|       25|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000092|5/23/2009|      null|  BERKLEY, CARLTON|   IND| null|   null|     null|        M| New York|   NY|10035|            SECURITY|   JOHN JAY COLLEGE|     899|         10TH AVENUE|        New York|      NY|  40|       40|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|        H|     9|     ABC|  null|      null|R0000095|5/13/2009|      null|        KOCH, ERIC|   IND| null|   null|     null|        M| New York|   NY|10033|                null|            RETIRED|    null|                null|            null|    null|  20|       20|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "+--------+--------+-------+--------+-------------+---------+------+--------+------+----------+--------+---------+----------+------------------+------+-----+-------+---------+---------+---------+-----+-----+--------------------+-------------------+--------+--------------------+----------------+--------+----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2cRNc4wNFgt",
        "outputId": "db528d83-051a-4b26-8b71-ae189bf5ffca"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','INTERMNO', 'REFUNDDATE', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+-------+--------+-------------+---------+------------------+------+---------+---------+-----+-----+--------+----+---------+--------+----------+\n",
            "|ELECTION|OFFICECD|RECIPID|CANCLASS|    RECIPNAME|     DATE|              NAME|C_CODE|BOROUGHCD|     CITY|STATE|  ZIP|EMPSTATE|AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|\n",
            "+--------+--------+-------+--------+-------------+---------+------------------+------+---------+---------+-----+-----+--------+----+---------+--------+----------+\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|1/22/2009|     Morris, Blake|   IND|        K| Brooklyn|   NY|11226|      NY| 100|      100|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen| 2/3/2009|     Pikttch, Ruth|   IND|        K| Brooklyn|   NY|11214|      NY|  50|       50|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|1/22/2009| Goldstein, Benita|   IND|        M| New York|   NY|10021|      NY|  40|       40|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|11/6/2008|     GOODWIN, GWEN|   CAN|        M| New York|   NY|10029|      NY|  25|        0|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|2/26/2009|   Anderson, Peter|   IND|        M| New York|   NY|10037|      NY|  40|       40|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|11/6/2008|     GOODWIN, GWEN|   CAN|        M| New York|   NY|10029|      NY|  25|        0|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|3/28/2009|     Perez, Andrew|   IND|        M| New York|   NY|10028|      NY|  10|       10|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen| 5/4/2009|    Rodriguez, Ana|   IND|        M| New York|   NY|10029|      NY|  15|       15|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|4/14/2009|  Bryant, Robert A|   IND|        Z|Hillcrest|   NY|10977|    null| 100|        0|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|3/16/2009| Reinert, Pamela A|   IND|        M| New York|   NY|10029|    null| 250|      175|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen| 5/4/2009|Palmieri, Pasquale|   IND|        M| New York|   NY|10035|      NY| 500|      175|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen| 5/2/2009|       Bruno, Jo C|   IND|        M| New York|   NY|10017|    null|  25|       25|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/14/2009|    Epstein, Lorie|   IND|        M| New York|   NY|10128|    null|  10|       10|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/23/2009|   BROWN, FRANCINE|   IND|        M| New York|   NY|10037|      NY|  20|       20|       0|         2|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/23/2009|    ASHANTE, OMEGA|   IND|        K| Brooklyn|   NY|11226|    null|  10|       10|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/23/2009| Reinert, Pamela A|   IND|        M| New York|   NY|10029|    null|  20|        0|     250|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/23/2009|      SOLER, JAMES|   IND|        M| New York|   NY|10029|    null|  50|       50|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/23/2009|   DELUCA, ANTHONY|   IND|        M| New York|   NY|10025|      NY|  25|       25|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/23/2009|  BERKLEY, CARLTON|   IND|        M| New York|   NY|10035|      NY|  40|       40|       0|         1|\n",
            "|    2009|       5|   1009|       P|Goodwin, Gwen|5/13/2009|        KOCH, ERIC|   IND|        M| New York|   NY|10033|    null|  20|       20|       0|         2|\n",
            "+--------+--------+-------+--------+-------------+---------+------------------+------+---------+---------+-----+-----+--------+----+---------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5aiRN5RNFjB",
        "outputId": "0ab70c71-0425-403c-f849-abf84a6b9ca2"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ELECTION', 'string'),\n",
              " ('OFFICECD', 'string'),\n",
              " ('RECIPID', 'string'),\n",
              " ('CANCLASS', 'string'),\n",
              " ('RECIPNAME', 'string'),\n",
              " ('DATE', 'string'),\n",
              " ('NAME', 'string'),\n",
              " ('C_CODE', 'string'),\n",
              " ('BOROUGHCD', 'string'),\n",
              " ('CITY', 'string'),\n",
              " ('STATE', 'string'),\n",
              " ('ZIP', 'string'),\n",
              " ('EMPSTATE', 'string'),\n",
              " ('AMNT', 'string'),\n",
              " ('MATCHAMNT', 'string'),\n",
              " ('PREVAMNT', 'string'),\n",
              " ('PAY_METHOD', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIkq3wdqOzWV",
        "outputId": "762e3f9b-c6a6-43f8-8bd9-521b0ec1c15e"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\")\n",
        "\n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Election: string (nullable = true)\n",
            " |-- OFFICECD: string (nullable = true)\n",
            " |-- CandidateID: string (nullable = true)\n",
            " |-- CANCLASS: string (nullable = true)\n",
            " |-- CandidateName: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ContributerType: string (nullable = true)\n",
            " |-- BoroughName: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- ZipCode: string (nullable = true)\n",
            " |-- ContributionState: string (nullable = true)\n",
            " |-- Amount: string (nullable = true)\n",
            " |-- MatchAmt: string (nullable = true)\n",
            " |-- PrevAmt: string (nullable = true)\n",
            " |-- PayMethod: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p5HwOCEjlsd"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbyFIRMwjlzM",
        "outputId": "03153f24-1dfd-4d97-b61d-6fc7c2306152"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\", df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Election: integer (nullable = true)\n",
            " |-- OFFICECD: integer (nullable = true)\n",
            " |-- CandidateID: integer (nullable = true)\n",
            " |-- CANCLASS: string (nullable = true)\n",
            " |-- CandidateName: string (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ContributerType: string (nullable = true)\n",
            " |-- BoroughName: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- ZipCode: integer (nullable = true)\n",
            " |-- ContributionState: string (nullable = true)\n",
            " |-- Amount: float (nullable = true)\n",
            " |-- MatchAmt: float (nullable = true)\n",
            " |-- PrevAmt: float (nullable = true)\n",
            " |-- PayMethod: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1aCPuV3WPwC"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDLKVpihXzJY"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4JAvyQWRl7"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "fM_kC3ViNFqN",
        "outputId": "46c3323b-01ed-4159-e6b4-5685d2df393f"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PythonException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-74713dcfdb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Call only Mayor (1) and particaptes (P) within Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOFFICECD\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCANCLASS\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 223, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 212, in _batched\n    for item in iterator:\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 88, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-11-ab9f23780e70>\", line 3, in <lambda>\nTypeError: strptime() argument 1 must be str, not None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdLbDEzQAyc"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kbDs5ApZtEu"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4uude7r_d_-"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdRMcW-9mtO"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_indiv_2009_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_indiv_2009_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAV3a6jXmJTP"
      },
      "source": [
        "#Export to Clean CSV\n",
        "clean_indiv_2009_df.toPandas().to_csv(\"Clean_Indivdual_2009.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7gDM4IKH8Y"
      },
      "source": [
        "## **2009 Committee Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hraQT1VmLOhL"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Committee+Contributions+2009+(X).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Committee+Contributions+2009+(X).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-dAX_VzLOhL"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','REFUNDDATE','INTERMNO', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btba2GO-LOhL"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3HO9e01LOhL"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\") \n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAf4vA_5jTRM"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8pcOHEWjVfK"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\",df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6S4he5LOhM"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKU4a2YeLOhM"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH99qC5LOhM"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO9XHx_6LOhM"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEmNuKUFLOhM"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myx_AWPaLOhM"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEu2eqWaDg1J"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uci_zuD5LOhM"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_comm_2009_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_comm_2009_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP38ou7rs5hY"
      },
      "source": [
        "#Export to new CSV\n",
        "clean_comm_2009_df.toPandas().to_csv(\"Clean_Committee_2009.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3PsGBmTLOhN"
      },
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "#Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://database-final.cjdbapst3wjf.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
        "config = {\"user\":\"postgres\",\n",
        "          \"password\": \"*******\",\n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ4dBFJKSG5J"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "#clean_indiv_2009_df.write.jdbc(url=jdbc_url, table='individual_2009', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpL71qCG1F2"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "#clean_comm_2009_df.write.jdbc(url=jdbc_url, table='committee_2009', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}