{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2005_Contributions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLXjebAuDUwdu8KS9SZDaD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssheggrud/Mod_20_Project/blob/05_Riley/2005_Contributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0_SOu8LIEc"
      },
      "source": [
        "## **2005 Indivdual Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddn5mqQ0M_R3",
        "outputId": "1ae5f5ca-d8fe-4c5b-b7c0-af6ce3abf53f"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.0.3'\n",
        "#spark_version = 'spark-2.4.8'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Co\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Co\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.39)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiP19KLKCpxR"
      },
      "source": [
        "import findspark\n",
        "findspark.add_packages('mysql:mysql-connector-java:8.0.11')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Dd_JabNFZU",
        "outputId": "0989a589-f335-48a0-8724-fa84893e8497"
      },
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 18:31:19--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.6’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  1.69MB/s    in 0.6s    \n",
            "\n",
            "2021-09-14 18:31:21 (1.69 MB/s) - ‘postgresql-42.2.16.jar.6’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrvolWKMNFbe"
      },
      "source": [
        "# Start Spark session\n",
        "#from pyspark.sql import SparkSession\n",
        "#from pyspark.sql.functions import col\n",
        "#spark = SparkSession.builder.appName(\"FinalProject\").getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9RnA4W6GDS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2uxnkAjNFeD",
        "outputId": "ddd38ef1-0783-41fc-a8c2-f24fa920d1b7"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Individual+Contributions+2005+(UF).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Individual+Contributions+2005+(UF).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-------------+----------+------+---------+------+--------+------+----------+--------+---------------+--------------+--------------------+------+------+------------------+---------+---------+-------------+-----+-----+----------+-------+--------+----------+-------+--------+-----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|     CANDLAST| CANDFIRST|CANDMI|COMMITTEE|FILING|SCHEDULE|PAGENO|SEQUENCENO|   REFNO|           DATE|    REFUNDDATE|                NAME|C_CODE| STRNO|           STRNAME|APARTMENT|BOROUGHCD|         CITY|STATE|  ZIP|OCCUPATION|EMPNAME|EMPSTRNO|EMPSTRNAME|EMPCITY|EMPSTATE| AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|INTERMNO|INTERMNAME|INTSTRNO|INTSTRNM|INTAPTNO|INTCITY|INTST|INTZIP|INTEMPNAME|INTEMPSTNO|INTEMPSTNM|INTEMPCITY|INTEMPST|INTOCCUPA|PURPOSECD|EXEMPTCD|ADJTYPECD|RR_IND|SEG_IND|INT_C_CODE|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------+------+--------+------+----------+--------+---------------+--------------+--------------------+------+------+------------------+---------+---------+-------------+-----+-----+----------+-------+--------+----------+-------+--------+-----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|    2005|       5|   863|       P|        Samad|    Maryam|     A|        H|    10|     ABC|  null|      null|R0000140| 5/13/2005 0:00|          null|(Head) Coach, Big...|   IND|  null|              null|     null|        K|     Brooklyn|   NY|11212|      null|   None|    null|      null|   null|    null|   10|       10|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|    E9|       P|     Marshall|     Helen|     M|        J|     5|     ABC|  null|      null|R0002434| 4/27/2004 0:00|          null|     005 New Gen LLC|   LLC|136-26|      37th. Avenue|     null|        Q|       Queens|   NY|11354|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|        I|    13|     ABC|  null|      null|R0000852|  9/4/2005 0:00|          null|         02 LIFE LLC|   LLC|   156|   Bay 14th Street|     null|        K|     Brooklyn|   NY|11214|      null|   null|    null|      null|   null|    null|  200|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       3|   260|       P|Thompson, Jr.|   William|     C|        J|     4|     ABC|  null|      null|R0005598|10/12/2003 0:00|          null|1 Christopher Rea...|   LLC|     1|Christopher Street|     null|        M|     New York|   NY|10014|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       1|    BB|       P|       Weiner|   Anthony|     D|        H|     8|     ABC|  null|      null|R0005497| 4/12/2005 0:00|          null|10 West 47th Stre...|   LLC|    10|      West 47th St|     null|        M|     New York|   NY|10036|      null|   null|    null|      null|   null|    null| 2500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|    ED|       P| Carrion, Jr.|    Adolfo|  null|        J|     3|     ABC|  null|      null|R0002613|  5/7/2003 0:00|          null|100 Mosholu Parkw...|  PART|   145|      Huguenot St.|     null|        Z| New Rochelle|   NY|10801|      null|   null|    null|      null|   null|    null|  350|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null|        K|     8|     ABC|  null|      null|R0004101| 7/15/2004 0:00|          null|101 West 75th St ...|   LLC|   101|         W 75th St|     null|        M|     New York|   NY|10023|      null|   null|    null|      null|   null|    null|  250|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|        I|    10|     ABC|  null|      null|R0000548| 6/20/2005 0:00|          null|105 Street Associ...|   LLC|  3092|       Hull Avenue|      # 4|        X|        Bronx|   NY|10467|      null|   null|    null|      null|   null|    null|  100|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   444|       P|        Dilan|      Erik|     M|        J|     8|     ABC|  null|      null|R0000482| 3/28/2005 0:00|          null|108 Central Assoc...|   LLC|    11|    Horseshoe Lane|     null|        Z|   Great Neck|   NY|11020|      null|   null|    null|      null|   null|    null|   75|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F|        J|    10|     ABC|  null|      null|R0001483| 5/25/2005 0:00|          null|108 Central Assoc...|   LLC|    11|    Horseshoe Lane|     null|        Z|   Great Neck|   NY|11020|      null|   null|    null|      null|   null|    null|   75|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null|        K|     8|     ABC|  null|      null|R0002838| 5/12/2004 0:00|          null|     10th STreet LLC|   LLC|     5|    N. 11th Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 5000|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|        H|     4|     ABC|  null|      null|R0004198|11/18/2003 0:00|          null|     10th Street LLC|   LLC|     5|      N. 11 Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 1000|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|        H|     5|     ABC|  null|      null|R0006786| 6/24/2004 0:00|          null|     10th Street LLC|   LLC|     5|      N. 11 Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 2850|        0|    1000|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null|        K|     8|       M|  null|      null|R0004390| 5/12/2004 0:00|5/11/2005 0:00|     10th STreet LLC|   LLC|     5|    N. 11th Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null|-2250|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|        5|     N|      N|      null|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|        I|     8|     ABC|  null|      null|R0016541|  5/9/2005 0:00|          null|    10th Street, LLC|   LLC|     5| North 11th Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 2000|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|        J|     5|     ABC|  null|      null|R0000548| 5/24/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|     Hubert Street|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|        J|     6|     ABC|  null|      null|R0000879|11/22/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|     Hubert Street|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  250|        0|     500|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F|        J|     5|     ABC|  null|      null|R0000766| 5/20/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|         Hubert St|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  250|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   204|       P|        Quinn| Christine|     C|        K|     6|     ABC|  null|      null|R0001474|10/28/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|     Hubert Street|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|        I|    15|     ABC|  null|      null|R0026538|10/17/2005 0:00|          null|112 South Whitney...|   LLC|   106|       Kane Street|     null|        Z|West Hartford|   CT| 6119|      null|   null|    null|      null|   null|    null|  125|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------+------+--------+------+----------+--------+---------------+--------------+--------------------+------+------+------------------+---------+---------+-------------+-----+-----+----------+-------+--------+----------+-------+--------+-----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2cRNc4wNFgt",
        "outputId": "e67b3494-e0fb-49ee-dd4b-64ee53e2b475"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTATE', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','INTERMNO', 'REFUNDDATE', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+-----+---------+--------+----------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|     CANDLAST| CANDFIRST|CANDMI|           DATE|                NAME|C_CODE|BOROUGHCD|         CITY|STATE|  ZIP| AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+-----+---------+--------+----------+\n",
            "|    2005|       5|   863|       P|        Samad|    Maryam|     A| 5/13/2005 0:00|(Head) Coach, Big...|   IND|        K|     Brooklyn|   NY|11212|   10|       10|       0|         1|\n",
            "|    2005|       4|    E9|       P|     Marshall|     Helen|     M| 4/27/2004 0:00|     005 New Gen LLC|   LLC|        Q|       Queens|   NY|11354|  500|        0|       0|         2|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|  9/4/2005 0:00|         02 LIFE LLC|   LLC|        K|     Brooklyn|   NY|11214|  200|        0|       0|         2|\n",
            "|    2005|       3|   260|       P|Thompson, Jr.|   William|     C|10/12/2003 0:00|1 Christopher Rea...|   LLC|        M|     New York|   NY|10014|  500|        0|       0|         2|\n",
            "|    2005|       1|    BB|       P|       Weiner|   Anthony|     D| 4/12/2005 0:00|10 West 47th Stre...|   LLC|        M|     New York|   NY|10036| 2500|        0|       0|         2|\n",
            "|    2005|       4|    ED|       P| Carrion, Jr.|    Adolfo|  null|  5/7/2003 0:00|100 Mosholu Parkw...|  PART|        Z| New Rochelle|   NY|10801|  350|        0|       0|         2|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 7/15/2004 0:00|101 West 75th St ...|   LLC|        M|     New York|   NY|10023|  250|        0|       0|         2|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null| 6/20/2005 0:00|105 Street Associ...|   LLC|        X|        Bronx|   NY|10467|  100|        0|       0|         2|\n",
            "|    2005|       5|   444|       P|        Dilan|      Erik|     M| 3/28/2005 0:00|108 Central Assoc...|   LLC|        Z|   Great Neck|   NY|11020|   75|        0|       0|         2|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F| 5/25/2005 0:00|108 Central Assoc...|   LLC|        Z|   Great Neck|   NY|11020|   75|        0|       0|         2|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 5/12/2004 0:00|     10th STreet LLC|   LLC|        K|     Brooklyn|   NY|11211| 5000|        0|       0|         2|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|11/18/2003 0:00|     10th Street LLC|   LLC|        K|     Brooklyn|   NY|11211| 1000|        0|       0|         2|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null| 6/24/2004 0:00|     10th Street LLC|   LLC|        K|     Brooklyn|   NY|11211| 2850|        0|    1000|         2|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 5/12/2004 0:00|     10th STreet LLC|   LLC|        K|     Brooklyn|   NY|11211|-2250|        0|       0|         0|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|  5/9/2005 0:00|    10th Street, LLC|   LLC|        K|     Brooklyn|   NY|11211| 2000|        0|       0|         2|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null| 5/24/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  500|        0|       0|         2|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|11/22/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  250|        0|     500|         2|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F| 5/20/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  250|        0|       0|         2|\n",
            "|    2005|       5|   204|       P|        Quinn| Christine|     C|10/28/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  500|        0|       0|         2|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|10/17/2005 0:00|112 South Whitney...|   LLC|        Z|West Hartford|   CT| 6119|  125|        0|       0|         2|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+-----+---------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5aiRN5RNFjB",
        "outputId": "077c6eb6-4a5d-42ec-ce54-6ea17af3fd07"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ELECTION', 'string'),\n",
              " ('OFFICECD', 'string'),\n",
              " ('CANDID', 'string'),\n",
              " ('CANCLASS', 'string'),\n",
              " ('CANDLAST', 'string'),\n",
              " ('CANDFIRST', 'string'),\n",
              " ('CANDMI', 'string'),\n",
              " ('DATE', 'string'),\n",
              " ('NAME', 'string'),\n",
              " ('C_CODE', 'string'),\n",
              " ('BOROUGHCD', 'string'),\n",
              " ('CITY', 'string'),\n",
              " ('STATE', 'string'),\n",
              " ('ZIP', 'string'),\n",
              " ('AMNT', 'string'),\n",
              " ('MATCHAMNT', 'string'),\n",
              " ('PREVAMNT', 'string'),\n",
              " ('PAY_METHOD', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK0-iptIKlH5"
      },
      "source": [
        "#TEST CODE FOR concat names DNU\n",
        "#from pyspark.sql.functions import concat,col\n",
        "#df1 = df.select(concat(df.CANDFIRST,df.CANDLAST)\n",
        " # .alias(\"CandidateName\"))\n",
        "#df1.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av3OwibjbTCF",
        "outputId": "4134f101-9f33-4b13-ada7-50173cd895a8"
      },
      "source": [
        "from pyspark.sql.functions import concat_ws\n",
        "df2 = df.withColumn(\"CandidateName\", concat_ws(\",\",\"CANDFIRST\",'CANDLAST')) \n",
        "df2.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+-----+---------+--------+----------+--------------------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|     CANDLAST| CANDFIRST|CANDMI|           DATE|                NAME|C_CODE|BOROUGHCD|         CITY|STATE|  ZIP| AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|       CandidateName|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+-----+---------+--------+----------+--------------------+\n",
            "|    2005|       5|   863|       P|        Samad|    Maryam|     A| 5/13/2005 0:00|(Head) Coach, Big...|   IND|        K|     Brooklyn|   NY|11212|   10|       10|       0|         1|        Maryam,Samad|\n",
            "|    2005|       4|    E9|       P|     Marshall|     Helen|     M| 4/27/2004 0:00|     005 New Gen LLC|   LLC|        Q|       Queens|   NY|11354|  500|        0|       0|         2|      Helen,Marshall|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|  9/4/2005 0:00|         02 LIFE LLC|   LLC|        K|     Brooklyn|   NY|11214|  200|        0|       0|         2|    Pasqualino,Russo|\n",
            "|    2005|       3|   260|       P|Thompson, Jr.|   William|     C|10/12/2003 0:00|1 Christopher Rea...|   LLC|        M|     New York|   NY|10014|  500|        0|       0|         2|William,Thompson,...|\n",
            "|    2005|       1|    BB|       P|       Weiner|   Anthony|     D| 4/12/2005 0:00|10 West 47th Stre...|   LLC|        M|     New York|   NY|10036| 2500|        0|       0|         2|      Anthony,Weiner|\n",
            "|    2005|       4|    ED|       P| Carrion, Jr.|    Adolfo|  null|  5/7/2003 0:00|100 Mosholu Parkw...|  PART|        Z| New Rochelle|   NY|10801|  350|        0|       0|         2| Adolfo,Carrion, Jr.|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 7/15/2004 0:00|101 West 75th St ...|   LLC|        M|     New York|   NY|10023|  250|        0|       0|         2|        David,Yassky|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null| 6/20/2005 0:00|105 Street Associ...|   LLC|        X|        Bronx|   NY|10467|  100|        0|       0|         2|    Pasqualino,Russo|\n",
            "|    2005|       5|   444|       P|        Dilan|      Erik|     M| 3/28/2005 0:00|108 Central Assoc...|   LLC|        Z|   Great Neck|   NY|11020|   75|        0|       0|         2|          Erik,Dilan|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F| 5/25/2005 0:00|108 Central Assoc...|   LLC|        Z|   Great Neck|   NY|11020|   75|        0|       0|         2|       James,Gennaro|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 5/12/2004 0:00|     10th STreet LLC|   LLC|        K|     Brooklyn|   NY|11211| 5000|        0|       0|         2|        David,Yassky|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|11/18/2003 0:00|     10th Street LLC|   LLC|        K|     Brooklyn|   NY|11211| 1000|        0|       0|         2|     Marty,Markowitz|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null| 6/24/2004 0:00|     10th Street LLC|   LLC|        K|     Brooklyn|   NY|11211| 2850|        0|    1000|         2|     Marty,Markowitz|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 5/12/2004 0:00|     10th STreet LLC|   LLC|        K|     Brooklyn|   NY|11211|-2250|        0|       0|         0|        David,Yassky|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|  5/9/2005 0:00|    10th Street, LLC|   LLC|        K|     Brooklyn|   NY|11211| 2000|        0|       0|         2|     Fernando,Ferrer|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null| 5/24/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  500|        0|       0|         2|         Tony,Avella|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|11/22/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  250|        0|     500|         2|         Tony,Avella|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F| 5/20/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  250|        0|       0|         2|       James,Gennaro|\n",
            "|    2005|       5|   204|       P|        Quinn| Christine|     C|10/28/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|  500|        0|       0|         2|     Christine,Quinn|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|10/17/2005 0:00|112 South Whitney...|   LLC|        Z|West Hartford|   CT| 6119|  125|        0|       0|         2|     Fernando,Ferrer|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+-----+---------+--------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcGhryiVhUD7"
      },
      "source": [
        "df3=df2.select('ELECTION','OFFICECD','CANDID','CANCLASS','CandidateName','DATE', 'NAME','C_CODE','BOROUGHCD','CITY','STATE', 'ZIP', 'AMNT', 'MATCHAMNT', 'PREVAMNT', 'PAY_METHOD')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIkq3wdqOzWV",
        "outputId": "81a6f01e-71ed-4b86-d16b-3b0d1d5e991a"
      },
      "source": [
        "#Change column names\n",
        "df4 = df3 \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"CANDID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\")\n",
        "\n",
        "df4.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Election: string (nullable = true)\n",
            " |-- OFFICECD: string (nullable = true)\n",
            " |-- CandidateID: string (nullable = true)\n",
            " |-- CANCLASS: string (nullable = true)\n",
            " |-- CandidateName: string (nullable = false)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ContributerType: string (nullable = true)\n",
            " |-- BoroughName: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- ZipCode: string (nullable = true)\n",
            " |-- Amount: string (nullable = true)\n",
            " |-- MatchAmt: string (nullable = true)\n",
            " |-- PrevAmt: string (nullable = true)\n",
            " |-- PayMethod: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p5HwOCEjlsd"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbyFIRMwjlzM",
        "outputId": "9b1204a6-a67d-46b4-e83d-b733f0df1292"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df5 = df4.withColumn(\"Election\", df4[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df4[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df4[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df4[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df4[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df4[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df4[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df5.printSchema()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Election: integer (nullable = true)\n",
            " |-- OFFICECD: integer (nullable = true)\n",
            " |-- CandidateID: integer (nullable = true)\n",
            " |-- CANCLASS: string (nullable = true)\n",
            " |-- CandidateName: string (nullable = false)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ContributerType: string (nullable = true)\n",
            " |-- BoroughName: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- ZipCode: integer (nullable = true)\n",
            " |-- Amount: float (nullable = true)\n",
            " |-- MatchAmt: float (nullable = true)\n",
            " |-- PrevAmt: float (nullable = true)\n",
            " |-- PayMethod: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1aCPuV3WPwC"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df6 = df5.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDLKVpihXzJY"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df7=df6.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4JAvyQWRl7"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df8 = df7.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "zvXpFYfgkaBG",
        "outputId": "fb033bc7-ae43-48f3-89e4-e75f6189e3a7"
      },
      "source": [
        "df8.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PythonException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-62b108daae3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 223, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 212, in _batched\n    for item in iterator:\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 88, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/content/spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-14-d5d5bdf6db86>\", line 3, in <lambda>\n  File \"/usr/lib/python3.7/_strptime.py\", line 577, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/usr/lib/python3.7/_strptime.py\", line 362, in _strptime\n    data_string[found.end():])\nValueError: unconverted data remains:  0:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM_kC3ViNFqN"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df9 = df8.filter((df8.OFFICECD==\"1\") & (df8.CANCLASS==\"P\"))\n",
        "df9.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdLbDEzQAyc"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df9.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kbDs5ApZtEu"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df10 = df9.drop(*list2)\n",
        "df10.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4uude7r_d_-"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df11 = df10.filter(df10.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdRMcW-9mtO"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_indiv_2005_df = df11.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_indiv_2005_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAV3a6jXmJTP"
      },
      "source": [
        "#Export to Clean CSV\n",
        "#clean_indiv_2005_df.toPandas().to_csv(\"Clean_Indivdual_2005.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7gDM4IKH8Y"
      },
      "source": [
        "## **2005 Committee Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hraQT1VmLOhL"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Committee+Contributions+2005+(X).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Committee+Contributions+2005+(X).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-dAX_VzLOhL"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','REFUNDDATE','INTERMNO', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btba2GO-LOhL"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3HO9e01LOhL"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\") \n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAf4vA_5jTRM"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8pcOHEWjVfK"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\",df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6S4he5LOhM"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKU4a2YeLOhM"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH99qC5LOhM"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO9XHx_6LOhM"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEmNuKUFLOhM"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myx_AWPaLOhM"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEu2eqWaDg1J"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uci_zuD5LOhM"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_comm_2005_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_comm_2005_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP38ou7rs5hY"
      },
      "source": [
        "#Export to new CSV\n",
        "clean_comm_2005_df.toPandas().to_csv(\"Clean_Committee_2005.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3PsGBmTLOhN"
      },
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "#Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://database-final.cjdbapst3wjf.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
        "config = {\"user\":\"postgres\",\n",
        "          \"password\": \"******\",\n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ4dBFJKSG5J"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "#clean_indiv_2005_df.write.jdbc(url=jdbc_url, table='individual_2005', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpL71qCG1F2"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "#clean_comm_2005_df.write.jdbc(url=jdbc_url, table='committee_2005', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}