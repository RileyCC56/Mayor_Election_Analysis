{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2005_Contributions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMj1EwLoBhJ8Q9Q10QiivE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssheggrud/Mod_20_Project/blob/05_Riley/2005_Contributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0_SOu8LIEc"
      },
      "source": [
        "## **2005 Indivdual Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddn5mqQ0M_R3",
        "outputId": "b3b2af21-2b3f-4877-9b13-30c7ee2874dc"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.0.3'\n",
        "#spark_version = 'spark-2.4.8'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 0 B/88.7 kB \r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 57.6 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 88.7 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to ppa.launch\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [567 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,324 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,799 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [717 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [921 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [600 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,760 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 13.6 MB in 5s (2,717 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiP19KLKCpxR"
      },
      "source": [
        "import findspark\n",
        "findspark.add_packages('mysql:mysql-connector-java:8.0.11')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Dd_JabNFZU",
        "outputId": "60142f6d-102e-4c26-efe1-5d6278fa4cf4"
      },
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 02:55:05--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  5.66MB/s    in 0.2s    \n",
            "\n",
            "2021-09-14 02:55:06 (5.66 MB/s) - ‘postgresql-42.2.16.jar’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrvolWKMNFbe"
      },
      "source": [
        "# Start Spark session\n",
        "#from pyspark.sql import SparkSession\n",
        "#from pyspark.sql.functions import col\n",
        "#spark = SparkSession.builder.appName(\"FinalProject\").getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9RnA4W6GDS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2uxnkAjNFeD",
        "outputId": "a64aafae-83e6-4c8b-e522-2ac1b02d8371"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Individual+Contributions+2005+(UF).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Individual+Contributions+2005+(UF).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-------------+----------+------+---------+------+--------+------+----------+--------+---------------+--------------+--------------------+------+------+------------------+---------+---------+-------------+-----+-----+----------+-------+--------+----------+-------+--------+-----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|     CANDLAST| CANDFIRST|CANDMI|COMMITTEE|FILING|SCHEDULE|PAGENO|SEQUENCENO|   REFNO|           DATE|    REFUNDDATE|                NAME|C_CODE| STRNO|           STRNAME|APARTMENT|BOROUGHCD|         CITY|STATE|  ZIP|OCCUPATION|EMPNAME|EMPSTRNO|EMPSTRNAME|EMPCITY|EMPSTATE| AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|INTERMNO|INTERMNAME|INTSTRNO|INTSTRNM|INTAPTNO|INTCITY|INTST|INTZIP|INTEMPNAME|INTEMPSTNO|INTEMPSTNM|INTEMPCITY|INTEMPST|INTOCCUPA|PURPOSECD|EXEMPTCD|ADJTYPECD|RR_IND|SEG_IND|INT_C_CODE|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------+------+--------+------+----------+--------+---------------+--------------+--------------------+------+------+------------------+---------+---------+-------------+-----+-----+----------+-------+--------+----------+-------+--------+-----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "|    2005|       5|   863|       P|        Samad|    Maryam|     A|        H|    10|     ABC|  null|      null|R0000140| 5/13/2005 0:00|          null|(Head) Coach, Big...|   IND|  null|              null|     null|        K|     Brooklyn|   NY|11212|      null|   None|    null|      null|   null|    null|   10|       10|       0|         1|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|    E9|       P|     Marshall|     Helen|     M|        J|     5|     ABC|  null|      null|R0002434| 4/27/2004 0:00|          null|     005 New Gen LLC|   LLC|136-26|      37th. Avenue|     null|        Q|       Queens|   NY|11354|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|        I|    13|     ABC|  null|      null|R0000852|  9/4/2005 0:00|          null|         02 LIFE LLC|   LLC|   156|   Bay 14th Street|     null|        K|     Brooklyn|   NY|11214|      null|   null|    null|      null|   null|    null|  200|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       3|   260|       P|Thompson, Jr.|   William|     C|        J|     4|     ABC|  null|      null|R0005598|10/12/2003 0:00|          null|1 Christopher Rea...|   LLC|     1|Christopher Street|     null|        M|     New York|   NY|10014|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       1|    BB|       P|       Weiner|   Anthony|     D|        H|     8|     ABC|  null|      null|R0005497| 4/12/2005 0:00|          null|10 West 47th Stre...|   LLC|    10|      West 47th St|     null|        M|     New York|   NY|10036|      null|   null|    null|      null|   null|    null| 2500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|    ED|       P| Carrion, Jr.|    Adolfo|  null|        J|     3|     ABC|  null|      null|R0002613|  5/7/2003 0:00|          null|100 Mosholu Parkw...|  PART|   145|      Huguenot St.|     null|        Z| New Rochelle|   NY|10801|      null|   null|    null|      null|   null|    null|  350|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null|        K|     8|     ABC|  null|      null|R0004101| 7/15/2004 0:00|          null|101 West 75th St ...|   LLC|   101|         W 75th St|     null|        M|     New York|   NY|10023|      null|   null|    null|      null|   null|    null|  250|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|        I|    10|     ABC|  null|      null|R0000548| 6/20/2005 0:00|          null|105 Street Associ...|   LLC|  3092|       Hull Avenue|      # 4|        X|        Bronx|   NY|10467|      null|   null|    null|      null|   null|    null|  100|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   444|       P|        Dilan|      Erik|     M|        J|     8|     ABC|  null|      null|R0000482| 3/28/2005 0:00|          null|108 Central Assoc...|   LLC|    11|    Horseshoe Lane|     null|        Z|   Great Neck|   NY|11020|      null|   null|    null|      null|   null|    null|   75|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F|        J|    10|     ABC|  null|      null|R0001483| 5/25/2005 0:00|          null|108 Central Assoc...|   LLC|    11|    Horseshoe Lane|     null|        Z|   Great Neck|   NY|11020|      null|   null|    null|      null|   null|    null|   75|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null|        K|     8|     ABC|  null|      null|R0002838| 5/12/2004 0:00|          null|     10th STreet LLC|   LLC|     5|    N. 11th Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 5000|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|        H|     4|     ABC|  null|      null|R0004198|11/18/2003 0:00|          null|     10th Street LLC|   LLC|     5|      N. 11 Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 1000|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|        H|     5|     ABC|  null|      null|R0006786| 6/24/2004 0:00|          null|     10th Street LLC|   LLC|     5|      N. 11 Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 2850|        0|    1000|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null|        K|     8|       M|  null|      null|R0004390| 5/12/2004 0:00|5/11/2005 0:00|     10th STreet LLC|   LLC|     5|    N. 11th Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null|-2250|        0|       0|         0|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|        5|     N|      N|      null|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|        I|     8|     ABC|  null|      null|R0016541|  5/9/2005 0:00|          null|    10th Street, LLC|   LLC|     5| North 11th Street|     null|        K|     Brooklyn|   NY|11211|      null|   null|    null|      null|   null|    null| 2000|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|        J|     5|     ABC|  null|      null|R0000548| 5/24/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|     Hubert Street|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|        J|     6|     ABC|  null|      null|R0000879|11/22/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|     Hubert Street|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  250|        0|     500|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F|        J|     5|     ABC|  null|      null|R0000766| 5/20/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|         Hubert St|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  250|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       5|   204|       P|        Quinn| Christine|     C|        K|     6|     ABC|  null|      null|R0001474|10/28/2004 0:00|          null|11-13 Hubert Stre...|   LLC|    11|     Hubert Street|     null|        M|     New York|   NY|10013|      null|   null|    null|      null|   null|    null|  500|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|        I|    15|     ABC|  null|      null|R0026538|10/17/2005 0:00|          null|112 South Whitney...|   LLC|   106|       Kane Street|     null|        Z|West Hartford|   CT| 6119|      null|   null|    null|      null|   null|    null|  125|        0|       0|         2|    null|      null|    null|    null|    null|   null| null|  null|      null|      null|      null|      null|    null|     null|     null|    null|     null|     N|      N|      null|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------+------+--------+------+----------+--------+---------------+--------------+--------------------+------+------+------------------+---------+---------+-------------+-----+-----+----------+-------+--------+----------+-------+--------+-----+---------+--------+----------+--------+----------+--------+--------+--------+-------+-----+------+----------+----------+----------+----------+--------+---------+---------+--------+---------+------+-------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2cRNc4wNFgt",
        "outputId": "a41804c8-5a1f-48e1-a65f-bdef6a3844a7"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','INTERMNO', 'REFUNDDATE', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+--------+-----+---------+--------+----------+\n",
            "|ELECTION|OFFICECD|CANDID|CANCLASS|     CANDLAST| CANDFIRST|CANDMI|           DATE|                NAME|C_CODE|BOROUGHCD|         CITY|STATE|  ZIP|EMPSTATE| AMNT|MATCHAMNT|PREVAMNT|PAY_METHOD|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+--------+-----+---------+--------+----------+\n",
            "|    2005|       5|   863|       P|        Samad|    Maryam|     A| 5/13/2005 0:00|(Head) Coach, Big...|   IND|        K|     Brooklyn|   NY|11212|    null|   10|       10|       0|         1|\n",
            "|    2005|       4|    E9|       P|     Marshall|     Helen|     M| 4/27/2004 0:00|     005 New Gen LLC|   LLC|        Q|       Queens|   NY|11354|    null|  500|        0|       0|         2|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null|  9/4/2005 0:00|         02 LIFE LLC|   LLC|        K|     Brooklyn|   NY|11214|    null|  200|        0|       0|         2|\n",
            "|    2005|       3|   260|       P|Thompson, Jr.|   William|     C|10/12/2003 0:00|1 Christopher Rea...|   LLC|        M|     New York|   NY|10014|    null|  500|        0|       0|         2|\n",
            "|    2005|       1|    BB|       P|       Weiner|   Anthony|     D| 4/12/2005 0:00|10 West 47th Stre...|   LLC|        M|     New York|   NY|10036|    null| 2500|        0|       0|         2|\n",
            "|    2005|       4|    ED|       P| Carrion, Jr.|    Adolfo|  null|  5/7/2003 0:00|100 Mosholu Parkw...|  PART|        Z| New Rochelle|   NY|10801|    null|  350|        0|       0|         2|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 7/15/2004 0:00|101 West 75th St ...|   LLC|        M|     New York|   NY|10023|    null|  250|        0|       0|         2|\n",
            "|    2005|       5|   758|       P|        Russo|Pasqualino|  null| 6/20/2005 0:00|105 Street Associ...|   LLC|        X|        Bronx|   NY|10467|    null|  100|        0|       0|         2|\n",
            "|    2005|       5|   444|       P|        Dilan|      Erik|     M| 3/28/2005 0:00|108 Central Assoc...|   LLC|        Z|   Great Neck|   NY|11020|    null|   75|        0|       0|         2|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F| 5/25/2005 0:00|108 Central Assoc...|   LLC|        Z|   Great Neck|   NY|11020|    null|   75|        0|       0|         2|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 5/12/2004 0:00|     10th STreet LLC|   LLC|        K|     Brooklyn|   NY|11211|    null| 5000|        0|       0|         2|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null|11/18/2003 0:00|     10th Street LLC|   LLC|        K|     Brooklyn|   NY|11211|    null| 1000|        0|       0|         2|\n",
            "|    2005|       4|   226|       P|    Markowitz|     Marty|  null| 6/24/2004 0:00|     10th Street LLC|   LLC|        K|     Brooklyn|   NY|11211|    null| 2850|        0|    1000|         2|\n",
            "|    2005|       5|   280|       P|       Yassky|     David|  null| 5/12/2004 0:00|     10th STreet LLC|   LLC|        K|     Brooklyn|   NY|11211|    null|-2250|        0|       0|         0|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|  5/9/2005 0:00|    10th Street, LLC|   LLC|        K|     Brooklyn|   NY|11211|    null| 2000|        0|       0|         2|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null| 5/24/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|    null|  500|        0|       0|         2|\n",
            "|    2005|       5|    51|       P|       Avella|      Tony|  null|11/22/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|    null|  250|        0|     500|         2|\n",
            "|    2005|       5|   283|       P|      Gennaro|     James|     F| 5/20/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|    null|  250|        0|       0|         2|\n",
            "|    2005|       5|   204|       P|        Quinn| Christine|     C|10/28/2004 0:00|11-13 Hubert Stre...|   LLC|        M|     New York|   NY|10013|    null|  500|        0|       0|         2|\n",
            "|    2005|       1|    AY|       P|       Ferrer|  Fernando|  null|10/17/2005 0:00|112 South Whitney...|   LLC|        Z|West Hartford|   CT| 6119|    null|  125|        0|       0|         2|\n",
            "+--------+--------+------+--------+-------------+----------+------+---------------+--------------------+------+---------+-------------+-----+-----+--------+-----+---------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5aiRN5RNFjB",
        "outputId": "b81acfb3-64c5-4256-f730-d7c35aaaa33c"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ELECTION', 'string'),\n",
              " ('OFFICECD', 'string'),\n",
              " ('CANDID', 'string'),\n",
              " ('CANCLASS', 'string'),\n",
              " ('CANDLAST', 'string'),\n",
              " ('CANDFIRST', 'string'),\n",
              " ('CANDMI', 'string'),\n",
              " ('DATE', 'string'),\n",
              " ('NAME', 'string'),\n",
              " ('C_CODE', 'string'),\n",
              " ('BOROUGHCD', 'string'),\n",
              " ('CITY', 'string'),\n",
              " ('STATE', 'string'),\n",
              " ('ZIP', 'string'),\n",
              " ('EMPSTATE', 'string'),\n",
              " ('AMNT', 'string'),\n",
              " ('MATCHAMNT', 'string'),\n",
              " ('PREVAMNT', 'string'),\n",
              " ('PAY_METHOD', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIkq3wdqOzWV",
        "outputId": "abc05740-40ba-44ad-9ff3-097a0153ef36"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\")\n",
        "\n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Election: string (nullable = true)\n",
            " |-- OFFICECD: string (nullable = true)\n",
            " |-- CANDID: string (nullable = true)\n",
            " |-- CANCLASS: string (nullable = true)\n",
            " |-- CANDLAST: string (nullable = true)\n",
            " |-- CANDFIRST: string (nullable = true)\n",
            " |-- CANDMI: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ContributerType: string (nullable = true)\n",
            " |-- BoroughName: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- ZipCode: string (nullable = true)\n",
            " |-- ContributionState: string (nullable = true)\n",
            " |-- Amount: string (nullable = true)\n",
            " |-- MatchAmt: string (nullable = true)\n",
            " |-- PrevAmt: string (nullable = true)\n",
            " |-- PayMethod: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p5HwOCEjlsd"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "dbyFIRMwjlzM",
        "outputId": "6efed922-f60f-4154-a17d-bcc894beb268"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\", df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ab9f23780e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# changing datatypes of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mudf\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDateType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Election\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Election\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OFFICECD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OFFICECD\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CandidateID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CandidateID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ZipCode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ZipCode\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Amount\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Amount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MatchAmt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MatchAmt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PrevAmt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PrevAmt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0...\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \"\"\"\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Cannot resolve column name \"CandidateID\" among (Election, OFFICECD, CANDID, CANCLASS, CANDLAST, CANDFIRST, CANDMI, Date, Name, ContributerType, BoroughName, City, State, ZipCode, ContributionState, Amount, MatchAmt, PrevAmt, PayMethod);"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1aCPuV3WPwC"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDLKVpihXzJY"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4JAvyQWRl7"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM_kC3ViNFqN"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdLbDEzQAyc"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kbDs5ApZtEu"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4uude7r_d_-"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdRMcW-9mtO"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_indiv_201705_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_indiv_2005_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAV3a6jXmJTP"
      },
      "source": [
        "#Export to Clean CSV\n",
        "clean_indiv_2005_df.toPandas().to_csv(\"Clean_Indivdual_2005.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7gDM4IKH8Y"
      },
      "source": [
        "## **2005 Committee Contributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hraQT1VmLOhL"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://databootcamp-final-05.s3.amazonaws.com/Resources/Committee+Contributions+2005+(X).csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"Committee+Contributions+2005+(X).csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-dAX_VzLOhL"
      },
      "source": [
        "# Remove multiple columns\n",
        "list = ['COMMITTEE', 'FILING', 'SCHEDULE', 'PAGENO', 'SEQUENCENO','REFNO', 'STRNO', 'STRNAME', 'APARTMENT', 'OCCUPATION', 'EMPNAME', 'EMPSTRNO', 'EMPSTRNAME',\n",
        "                'EMPCITY','REFUNDDATE','INTERMNO', 'INTERMNAME', 'INTSTRNO', 'INTSTRNM', 'INTSTRNM', 'INTAPTNO',\n",
        "                'INTCITY', 'INTST','INTZIP', 'INTEMPNAME', 'INTEMPSTNO', 'INTEMPSTNM', 'INTEMPCITY', 'INTEMPST', 'INTOCCUPA' ,'PURPOSECD', 'EXEMPTCD','ADJTYPECD', 'RR_IND', 'SEG_IND','INT_C_CODE'] \n",
        "df = df.drop(*list)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btba2GO-LOhL"
      },
      "source": [
        "# check data types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3HO9e01LOhL"
      },
      "source": [
        "#Change column names\n",
        "df1 = df \\\n",
        ".withColumnRenamed(\"ELECTION\", \"Election\") \\\n",
        ".withColumnRenamed(\"RECIPID\", \"CandidateID\") \\\n",
        ".withColumnRenamed(\"RECIPNAME\", \"CandidateName\") \\\n",
        ".withColumnRenamed(\"DATE\", \"Date\") \\\n",
        ".withColumnRenamed(\"NAME\", \"Name\") \\\n",
        ".withColumnRenamed(\"C_CODE\", \"ContributerType\") \\\n",
        ".withColumnRenamed(\"BOROUGHCD\", \"BoroughName\") \\\n",
        ".withColumnRenamed(\"CITY\", \"City\") \\\n",
        ".withColumnRenamed(\"STATE\", \"State\") \\\n",
        ".withColumnRenamed(\"ZIP\", \"ZipCode\") \\\n",
        ".withColumnRenamed(\"EMPSTATE\", \"ContributionState\") \\\n",
        ".withColumnRenamed(\"AMNT\", \"Amount\") \\\n",
        ".withColumnRenamed(\"MATCHAMNT\", \"MatchAmt\") \\\n",
        ".withColumnRenamed(\"PREVAMNT\", \"PrevAmt\") \\\n",
        ".withColumnRenamed(\"PAY_METHOD\", \"PayMethod\") \n",
        "\n",
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAf4vA_5jTRM"
      },
      "source": [
        "from datetime import datetime\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8pcOHEWjVfK"
      },
      "source": [
        "# using lambda function to convert date col to datetype\n",
        "# changing datatypes of columns\n",
        "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
        "df2 = df1.withColumn(\"Election\",df1[\"Election\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"OFFICECD\", df1[\"OFFICECD\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"CandidateID\", df1[\"CandidateID\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"ZipCode\", df1[\"ZipCode\"].cast(\"Integer\")) \\\n",
        "  .withColumn(\"Amount\", df1[\"Amount\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"MatchAmt\", df1[\"MatchAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn(\"PrevAmt\", df1[\"PrevAmt\"].cast(\"Float\")) \\\n",
        "  .withColumn('Date', func(col('Date')))\n",
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6S4he5LOhM"
      },
      "source": [
        "#Change vaule name in ContributerType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df3 = df2.withColumn('ContributerType', regexp_replace('ContributerType', 'CAN', 'Candidate')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'CORP', 'Corporation')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'EMPO', 'Labor Union')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'FAM', 'Candidate Family')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'IND', 'Individual')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMZ', 'Party Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'ORG', 'Orgainization')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'LLC', 'Limited Liability Company')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMP', 'Political Action Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'SPO', 'Spouse')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'OTHR', 'Other')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PCOMC', 'Candidate Committee')) \\\n",
        "  .withColumn('ContributerType', regexp_replace('ContributerType', 'PART', 'Individual')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKU4a2YeLOhM"
      },
      "source": [
        "#Change Payment Method Name\n",
        "df4=df3.withColumn('PayMethod', regexp_replace('PayMethod','0','Unknown')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','1','Cash')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','2','Check')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','3','Other')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','4','Credit Card')) \\\n",
        "  .withColumn('PayMethod', regexp_replace('PayMethod','5','Money Order')) \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH99qC5LOhM"
      },
      "source": [
        "#Change Borough name\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "df5 = df4.withColumn('BoroughName', regexp_replace('BoroughName', 'K', 'Brooklyn')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'M', 'Manhattan')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Q', 'Queens')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'S', 'Staten Island')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'X', 'Bronx')) \\\n",
        "  .withColumn('BoroughName', regexp_replace('BoroughName', 'Z', 'Other')) \\\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO9XHx_6LOhM"
      },
      "source": [
        "#Call only Mayor (1) and particaptes (P) within Dataframe\n",
        "df6 = df5.filter((df5.OFFICECD==\"1\") & (df5.CANCLASS==\"P\"))\n",
        "df6.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEmNuKUFLOhM"
      },
      "source": [
        "#Check the above dataframe to make sure only unique values between the OFFICECD is 1 \n",
        "df6.select('OFFICECD').distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myx_AWPaLOhM"
      },
      "source": [
        "#Drop OFFICECD and CANCLASS\n",
        "list2 = ['OFFICECD', 'CANCLASS'] \n",
        "df7 = df6.drop(*list2)\n",
        "df7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEu2eqWaDg1J"
      },
      "source": [
        "#Filter Dataframe removing the null CandidateID values\n",
        "df8 = df7.filter(df7.CandidateID.isNotNull())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uci_zuD5LOhM"
      },
      "source": [
        "# ADD AMNT and MATCHAMNT PrevAmnt\n",
        "from pyspark.sql.functions import col\n",
        "clean_comm_2005_df = df8.withColumn(\"TotalAmount\", col(\"Amount\")+col(\"MatchAmt\")+col('PrevAmt'))\n",
        "clean_comm_2005_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP38ou7rs5hY"
      },
      "source": [
        "#Export to new CSV\n",
        "clean_comm_2005_df.toPandas().to_csv(\"Clean_Committee_2005.csv\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3PsGBmTLOhN"
      },
      "source": [
        "# Store environmental variable\n",
        "from getpass import getpass\n",
        "#Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://database-final.cjdbapst3wjf.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
        "config = {\"user\":\"postgres\",\n",
        "          \"password\": \"******\",\n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ4dBFJKSG5J"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "#clean_indiv_2005_df.write.jdbc(url=jdbc_url, table='individual_2005', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpL71qCG1F2"
      },
      "source": [
        "# Write DataFrame to active_user table in RDS\n",
        "#clean_comm_2005_df.write.jdbc(url=jdbc_url, table='committee_2005', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}